{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pysr import PySRRegressor\n",
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [this article](https://arxiv.org/abs/2211.06393) J. Bayron Orjuela-Quintana et al. have found an explicit expression for the transfer function T(k):\n",
    "\n",
    "$$ T(k;\\omega_b,\\omega_m) = [1+59.0998\\ x^{1.49177}+4658.01\\ x^{4.02755}+3170.79\\ x^{6.06}+150.089\\ x^7.28478]^{-\\frac{1}{4}} $$\n",
    "\n",
    "where\n",
    "$$ x=\\frac{k\\ Mpc}{\\omega_m-\\omega_b} $$\n",
    "\n",
    "and $\\omega_i=\\Omega_i h^2$, where $h$ is the reduced Hubble constant and $\\Omega_i$ are the density parameters where $X = b,c,m,r,\\nu,\\gamma$ denotes baryons, CDM, pressure-less matter, radiation, neutrinos, photons, respectively.\n",
    "\n",
    "First of all, let's import T(k) from CLASS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl = pd.read_csv('TF_class.csv')\n",
    "df_cus = pd.read_csv('TF_custom.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate T(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.6781\n",
    "k = df_cl['k (h/Mpc)']/h\n",
    "omega_b = 0.0223828 #omega baryon\n",
    "omega_m = 0.1201075 #omega pressure-less matter\n",
    "x = k/(omega_m-omega_b)\n",
    "T = (1 + 59.0998 * x**1.49177 + 4658.01 * x**4.02755 + 3170.79 * x**6.06 + 150.089 * x**7.28478)**(-1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_cus['k (1/Mpc)'][4:],df_cus['T(k)'][4:], label='computed by CLASS', lw=2)\n",
    "plt.plot(k[0:len(k)-3],T[0:len(k)-3], label='analityc formula (from GA)', linestyle=\"--\", color='r')\n",
    "plt.xlabel(r'$k\\ [\\frac{1}{Mpc}]$')\n",
    "plt.ylabel(r'$T(k)$')\n",
    "plt.title(r\"Matter transfer function $T(k)$\")\n",
    "plt.loglog()\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't understand why I obtain a good accordance while I'm neglecting that the numerator of x is adimensional ($k\\ Mpc$): in fact I used in the calculation only $k$, wich is dimensional ($[k]=\\frac{1}{Mpc}$).\n",
    "\n",
    "However, let's try to fit the analytic expression using PySR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obv = np.full(len(k), omega_b)\n",
    "omv = np.full(len(k), omega_m)\n",
    "X = np.vstack((k.values, omv, obv))\n",
    "x = x.values.reshape(-1,1)\n",
    "cluster = [\"slurm\", \"pbs\", \"lsf\", \"sge\", \"qrsh\", \"scyld\", \"htc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PySRRegressor(\n",
    "    niterations=100,  # < Increase me for better results\n",
    "    binary_operators=[\"+\", \"*\",'-','/',\"pow\"],\n",
    "    constraints={'pow': (-1, 2)},\n",
    "    nested_constraints={\"pow\": {\"pow\": 2}},\n",
    "    maxsize=40,\n",
    "    #unary_operators=[\n",
    "    #    \"exp\",\n",
    "    #    \"log\",\n",
    "    #],\n",
    "    loss=\"loss(prediction, target) = (prediction - target)^2\",\n",
    "    # ^ Custom loss function (julia syntax)\n",
    "    turbo=True,  \n",
    "    cluster_manager=cluster[0],\n",
    "    multithreading=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f\"The model has this equation as output: ${model.latex()}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x)\n",
    "diff = T-pred\n",
    "err = 100*abs(diff)/T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(9,18))\n",
    "\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.plot(k,pred, label='analityc formula (from PySR)', lw=2)\n",
    "ax1.plot(k,T, label='analityc formula (from GA)', linestyle=\"--\", color='r')\n",
    "ax1.set_xlabel(r'$k \\,\\,\\,\\, [1/\\mathrm{Mpc}]$')\n",
    "ax1.set_ylabel(r'$T(k)$')\n",
    "ax1.set_title('Transfer function T(k)')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_xlabel(r'$k \\,\\,\\,\\, [1/\\mathrm{Mpc}]$')\n",
    "ax2.set_ylabel(r'GA-PySR$')\n",
    "ax2.plot(k,diff)\n",
    "ax2.set_title('Difference between the formula and data')\n",
    "\n",
    "ax3.set_xlabel(r'$k \\,\\,\\,\\, [1/\\mathrm{Mpc}]$')\n",
    "ax3.set_ylabel(r'percentage error')\n",
    "ax3.plot(k,err)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simreg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
